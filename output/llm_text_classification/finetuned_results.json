[
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "과학",
        "num_standards": 190,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 98,
        "accuracy": 0.6533,
        "mrr": 0.6533,
        "exact_match_count": 150,
        "exact_match_percentage": 100.0,
        "match_type_distribution": {
            "exact": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "국어",
        "num_standards": 209,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 24,
        "accuracy": 0.16,
        "mrr": 0.16,
        "exact_match_count": 104,
        "exact_match_percentage": 69.33,
        "match_type_distribution": {
            "exact": 69.33,
            "invalid": 29.33,
            "partial": 1.33
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "기술가정",
        "num_standards": 86,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 53,
        "accuracy": 0.3533,
        "mrr": 0.3533,
        "exact_match_count": 150,
        "exact_match_percentage": 100.0,
        "match_type_distribution": {
            "exact": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "도덕",
        "num_standards": 21,
        "num_candidates": 21,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 63,
        "correct": 18,
        "accuracy": 0.2857,
        "mrr": 0.2857,
        "exact_match_count": 60,
        "exact_match_percentage": 95.24,
        "match_type_distribution": {
            "exact": 95.24,
            "invalid": 4.76
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "사회",
        "num_standards": 173,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 70,
        "accuracy": 0.4667,
        "mrr": 0.4667,
        "exact_match_count": 150,
        "exact_match_percentage": 100.0,
        "match_type_distribution": {
            "exact": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "사회문화",
        "num_standards": 13,
        "num_candidates": 13,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 39,
        "correct": 22,
        "accuracy": 0.5641,
        "mrr": 0.5641,
        "exact_match_count": 37,
        "exact_match_percentage": 94.87,
        "match_type_distribution": {
            "exact": 94.87,
            "partial": 2.56,
            "invalid": 2.56
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "수학",
        "num_standards": 241,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 43,
        "accuracy": 0.2867,
        "mrr": 0.2867,
        "exact_match_count": 111,
        "exact_match_percentage": 74.0,
        "match_type_distribution": {
            "invalid": 26.0,
            "exact": 74.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "영어",
        "num_standards": 84,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 8,
        "accuracy": 0.0533,
        "mrr": 0.0533,
        "exact_match_count": 112,
        "exact_match_percentage": 74.67,
        "match_type_distribution": {
            "invalid": 25.33,
            "exact": 74.67
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "정보",
        "num_standards": 54,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 38,
        "accuracy": 0.2533,
        "mrr": 0.2533,
        "exact_match_count": 139,
        "exact_match_percentage": 92.67,
        "match_type_distribution": {
            "exact": 92.67,
            "invalid": 7.33
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "과학",
        "num_standards": 190,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 200,
        "correct": 134,
        "accuracy": 0.67,
        "mrr": 0.67,
        "exact_match_count": 200,
        "exact_match_percentage": 100.0,
        "match_type_distribution": {
            "exact": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "국어",
        "num_standards": 209,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 200,
        "correct": 39,
        "accuracy": 0.195,
        "mrr": 0.195,
        "exact_match_count": 162,
        "exact_match_percentage": 81.0,
        "match_type_distribution": {
            "exact": 81.0,
            "invalid": 18.5,
            "partial": 0.5
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "기술가정",
        "num_standards": 86,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 200,
        "correct": 74,
        "accuracy": 0.37,
        "mrr": 0.37,
        "exact_match_count": 200,
        "exact_match_percentage": 100.0,
        "match_type_distribution": {
            "exact": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "도덕",
        "num_standards": 21,
        "num_candidates": 21,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 63,
        "correct": 17,
        "accuracy": 0.2698,
        "mrr": 0.2698,
        "exact_match_count": 42,
        "exact_match_percentage": 66.67,
        "match_type_distribution": {
            "invalid": 22.22,
            "exact": 66.67,
            "partial": 11.11
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "사회",
        "num_standards": 173,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 200,
        "correct": 110,
        "accuracy": 0.55,
        "mrr": 0.55,
        "exact_match_count": 196,
        "exact_match_percentage": 98.0,
        "match_type_distribution": {
            "exact": 98.0,
            "invalid": 2.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "사회문화",
        "num_standards": 13,
        "num_candidates": 13,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 39,
        "correct": 18,
        "accuracy": 0.4615,
        "mrr": 0.4615,
        "exact_match_count": 27,
        "exact_match_percentage": 69.23,
        "match_type_distribution": {
            "exact": 69.23,
            "invalid": 23.08,
            "partial": 7.69
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "수학",
        "num_standards": 241,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 200,
        "correct": 75,
        "accuracy": 0.375,
        "mrr": 0.375,
        "exact_match_count": 165,
        "exact_match_percentage": 82.5,
        "match_type_distribution": {
            "exact": 82.5,
            "invalid": 17.0,
            "partial": 0.5
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "영어",
        "num_standards": 84,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 200,
        "correct": 7,
        "accuracy": 0.035,
        "mrr": 0.035,
        "exact_match_count": 116,
        "exact_match_percentage": 58.0,
        "match_type_distribution": {
            "exact": 58.0,
            "invalid": 42.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/mnt/c/Users/ixezi/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "정보",
        "num_standards": 54,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 162,
        "correct": 32,
        "accuracy": 0.1975,
        "mrr": 0.1975,
        "exact_match_count": 140,
        "exact_match_percentage": 86.42,
        "match_type_distribution": {
            "exact": 86.42,
            "invalid": 13.58
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/mnt/c/Users/ixezi/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    }
]