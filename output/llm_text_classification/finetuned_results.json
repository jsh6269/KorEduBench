[
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "N/A",
        "subject": "과학",
        "num_standards": 190,
        "num_candidates": 120,
        "max_candidates": 120,
        "max_samples_per_row": 80,
        "total_samples": 100,
        "correct": 7,
        "accuracy": 0.07,
        "mrr": 0.07,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "partial": 87.0,
            "invalid": 13.0
        },
        "max_new_tokens": 50,
        "temperature": 0.1,
        "max_input_length": 6144,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {}
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "N/A",
        "subject": "국어",
        "num_standards": 209,
        "num_candidates": 120,
        "max_candidates": 120,
        "max_samples_per_row": 80,
        "total_samples": 100,
        "correct": 0,
        "accuracy": 0.0,
        "mrr": 0.0,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "partial": 87.0,
            "invalid": 13.0
        },
        "max_new_tokens": 50,
        "temperature": 0.1,
        "max_input_length": 6144,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {}
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "N/A",
        "subject": "기술가정",
        "num_standards": 86,
        "num_candidates": 86,
        "max_candidates": 120,
        "max_samples_per_row": 80,
        "total_samples": 100,
        "correct": 5,
        "accuracy": 0.05,
        "mrr": 0.05,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "partial": 100.0
        },
        "max_new_tokens": 50,
        "temperature": 0.1,
        "max_input_length": 6144,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {}
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "N/A",
        "subject": "도덕",
        "num_standards": 21,
        "num_candidates": 21,
        "max_candidates": 120,
        "max_samples_per_row": 80,
        "total_samples": 100,
        "correct": 19,
        "accuracy": 0.19,
        "mrr": 0.19,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "partial": 100.0
        },
        "max_new_tokens": 50,
        "temperature": 0.1,
        "max_input_length": 6144,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {}
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "과학",
        "num_standards": 190,
        "num_candidates": 60,
        "max_candidates": 60,
        "max_samples_per_row": 80,
        "total_samples": 100,
        "correct": 0,
        "accuracy": 0.0,
        "mrr": 0.0,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "invalid": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2048,
        "truncated_count": 100,
        "truncated_percentage": 100.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 2142,
            "num_train_epochs": 2,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0002,
            "max_seq_length": 2048,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "과학",
        "num_standards": 190,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 1,
        "accuracy": 0.0067,
        "mrr": 0.0067,
        "exact_match_count": 9,
        "exact_match_percentage": 6.0,
        "match_type_distribution": {
            "invalid": 94.0,
            "exact": 6.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "국어",
        "num_standards": 209,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 0,
        "accuracy": 0.0,
        "mrr": 0.0,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "invalid": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "기술가정",
        "num_standards": 86,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 1,
        "accuracy": 0.0067,
        "mrr": 0.0067,
        "exact_match_count": 54,
        "exact_match_percentage": 36.0,
        "match_type_distribution": {
            "invalid": 64.0,
            "exact": 36.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "도덕",
        "num_standards": 21,
        "num_candidates": 21,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 63,
        "correct": 9,
        "accuracy": 0.1429,
        "mrr": 0.1429,
        "exact_match_count": 63,
        "exact_match_percentage": 100.0,
        "match_type_distribution": {
            "exact": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "사회",
        "num_standards": 173,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 0,
        "accuracy": 0.0,
        "mrr": 0.0,
        "exact_match_count": 2,
        "exact_match_percentage": 1.33,
        "match_type_distribution": {
            "invalid": 98.67,
            "exact": 1.33
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "사회문화",
        "num_standards": 13,
        "num_candidates": 13,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 39,
        "correct": 0,
        "accuracy": 0.0,
        "mrr": 0.0,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "invalid": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "수학",
        "num_standards": 241,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 0,
        "accuracy": 0.0,
        "mrr": 0.0,
        "exact_match_count": 0,
        "exact_match_percentage": 0.0,
        "match_type_distribution": {
            "invalid": 100.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "영어",
        "num_standards": 84,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 0,
        "accuracy": 0.0,
        "mrr": 0.0,
        "exact_match_count": 3,
        "exact_match_percentage": 2.0,
        "match_type_distribution": {
            "invalid": 98.0,
            "exact": 2.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_llm",
        "base_model": "unsloth/Qwen2.5-7B-Instruct",
        "subject": "정보",
        "num_standards": 54,
        "num_candidates": 50,
        "max_candidates": 50,
        "max_samples_per_row": 3,
        "total_samples": 150,
        "correct": 2,
        "accuracy": 0.0133,
        "mrr": 0.0133,
        "exact_match_count": 43,
        "exact_match_percentage": 28.67,
        "match_type_distribution": {
            "invalid": 71.33,
            "exact": 28.67
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 4096,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct",
            "train_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/dataset/train_80",
            "num_examples": 21420,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 3000,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth"
        }
    }
]