[
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "과학",
        "num_standards": 190,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 146,
        "accuracy": 0.73,
        "match_type_distribution": {
            "exact": 97.0,
            "invalid": 3.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "국어",
        "num_standards": 209,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 75,
        "accuracy": 0.375,
        "match_type_distribution": {
            "exact": 86.0,
            "invalid": 13.0,
            "partial": 1.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "기술가정",
        "num_standards": 86,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 126,
        "accuracy": 0.63,
        "match_type_distribution": {
            "exact": 97.0,
            "invalid": 3.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "도덕",
        "num_standards": 21,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 140,
        "accuracy": 0.7,
        "match_type_distribution": {
            "exact": 99.5,
            "invalid": 0.5
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 1,
        "truncated_percentage": 0.5,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "사회",
        "num_standards": 173,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 133,
        "accuracy": 0.665,
        "match_type_distribution": {
            "exact": 97.5,
            "invalid": 2.5
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "사회문화",
        "num_standards": 13,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 146,
        "accuracy": 0.73,
        "match_type_distribution": {
            "exact": 88.5,
            "invalid": 11.5
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "수학",
        "num_standards": 241,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 103,
        "accuracy": 0.515,
        "match_type_distribution": {
            "invalid": 23.0,
            "exact": 73.0,
            "partial": 4.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "영어",
        "num_standards": 84,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 68,
        "accuracy": 0.34,
        "match_type_distribution": {
            "exact": 86.5,
            "invalid": 13.5
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    },
    {
        "folder": "valid_80",
        "model_path": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/finetuned_rag_llm/251127",
        "base_model": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "subject": "정보",
        "num_standards": 54,
        "top_k": 20,
        "total_samples": 200,
        "num_examples": 5,
        "correct": 74,
        "accuracy": 0.37,
        "match_type_distribution": {
            "exact": 78.0,
            "invalid": 22.0
        },
        "max_new_tokens": 20,
        "temperature": 0.1,
        "max_input_length": 2600,
        "truncated_count": 0,
        "truncated_percentage": 0.0,
        "training_info": {
            "model_name": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
            "model_dir": "/home/jeongmin/projects/2025_nlp/KorEduBench/model/achievement_classifier/best_model",
            "top_k": 20,
            "num_examples": 20220,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 4,
            "gradient_accumulation_steps": 4,
            "learning_rate": 0.0001,
            "max_seq_length": 2600,
            "lora_r": 16,
            "lora_alpha": 16,
            "lora_dropout": 0.0,
            "seed": 42,
            "load_in_4bit": true,
            "use_gradient_checkpointing": "unsloth",
            "few_shot": true,
            "num_examples_few_shot": 5
        }
    }
]